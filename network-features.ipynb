{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm, re, pandas as pd, random, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTxt(name):\n",
    "    return [i.strip() for i in open(f'../data/{name}', 'r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def someDump(df, name):\n",
    "    temp= {\n",
    "        'user': [], 'hashtagsCount': [], 'uniqueHashtagsCount': [], 'mentions': [], 'uniqueMentions': [], 'retweets': [],\n",
    "        'averageHashtagsCount': [], 'averageUniqueHashtagsCount': [], 'averageMentions': [], 'averageUniqueMentions': [],\n",
    "        'tweets': [], 'class': []\n",
    "    }\n",
    "    classUser= {\n",
    "        'suspended': 0,\n",
    "        'normal': 1,\n",
    "        'restored': 2\n",
    "    }\n",
    "    \n",
    "    for i in df:\n",
    "        temp['user'].append(i)\n",
    "        temp['tweets'].append(df[i]['tweets_count'])\n",
    "        temp['retweets'].append(df[i]['retweets_count'])\n",
    "        temp['class'].append(classUser[name])\n",
    "\n",
    "        temp['hashtagsCount'].append(len(df[i]['hashtags']))\n",
    "        temp['averageHashtagsCount'].append(len(df[i]['hashtags'])/df[i]['tweets_count'])\n",
    "        temp['uniqueHashtagsCount'].append(len(set(df[i]['hashtags'])))\n",
    "        temp['averageUniqueHashtagsCount'].append(len(set(df[i]['hashtags']))/df[i]['tweets_count'])\n",
    "\n",
    "        temp['mentions'].append(len(df[i]['mentions']))\n",
    "        temp['averageMentions'].append(len(df[i]['mentions'])/df[i]['tweets_count'])\n",
    "        temp['uniqueMentions'].append(len(set(df[i]['mentions'])))\n",
    "        temp['averageUniqueMentions'].append(len(set(df[i]['mentions']))/df[i]['tweets_count'])\n",
    "        \n",
    "    pd.DataFrame.from_dict(temp).to_csv(f'../data/network-{name}-features.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "restoredUsersList= set()\n",
    "for i in loadTxt('unsuspended_8_Oct.txt'):\n",
    "    restoredUsersList.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   CSV's Column: UserID, Class, No. User Mentions, No. Unique User Mentions, No. Retweets, No. Hashtags, No. Unique Hashtags \n",
    "'''\n",
    "normal= {}\n",
    "with open(f'../data/all_tweets_normal_jan3_2021.pickle', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            temp= pkl.load(f)\n",
    "            for i in tqdm.tqdm(temp):\n",
    "                user= i['user']['id_str']\n",
    "                if i.get('retweeted_status'):\n",
    "                    if normal.get(user) is None:\n",
    "                        normal[user]= {\n",
    "                            'hashtags': [j['text'] for j in i['entities']['hashtags']],\n",
    "                            'mentions': [j['id_str'] for j in i['entities']['user_mentions']],\n",
    "                            'tweets_count': 1,\n",
    "                            'retweets_count': 1\n",
    "                        }\n",
    "                    else:\n",
    "                        normal[user]['tweets_count']+= 1\n",
    "                        normal[user]['retweets_count']+= 1\n",
    "                elif i.get('full_text') or i.get('text'):\n",
    "                    if normal.get(user) is None:\n",
    "                        normal[user]= {\n",
    "                            'hashtags': [j['text'] for j in i['entities']['hashtags']],\n",
    "                            'mentions': [j['id_str'] for j in i['entities']['user_mentions']],\n",
    "                            'tweets_count': 1,\n",
    "                            'retweets_count': 0\n",
    "                        }\n",
    "                    else:\n",
    "                        normal[user]['tweets_count']+= 1\n",
    "                        for j in i['entities']['hashtags']:\n",
    "                            normal[user]['hashtags'].append(j['text'])\n",
    "                        for j in i['entities']['user_mentions']:\n",
    "                            normal[user]['mentions'].append(j['id_str'])\n",
    "                else:\n",
    "                    print('--'*20)\n",
    "                    pprint.pprint(i)\n",
    "                    break\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   CSV's Column: UserID, Class, No. User Mentions, No. Unique User Mentions, No. Retweets, No. Hashtags, No. Unique Hashtags \n",
    "'''\n",
    "suspended= {}\n",
    "restored= {}\n",
    "with open(f'../data/all_tweets_suspended_jan3_2021.pickle', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            temp= pkl.load(f)\n",
    "            for i in tqdm.tqdm(temp):\n",
    "                user= i['user']['id_str']\n",
    "                if i.get('retweeted_status'):\n",
    "                    if user in restoredUsersList:\n",
    "                        if restored.get(user) is None:\n",
    "                            restored[user]= {\n",
    "                                'hashtags': [j['text'] for j in i['entities']['hashtags']],\n",
    "                                'mentions': [j['id_str'] for j in i['entities']['user_mentions']],\n",
    "                                'tweets_count': 1,\n",
    "                                'retweets_count': 1\n",
    "                            }\n",
    "                        else:\n",
    "                            restored[user]['tweets_count']+= 1\n",
    "                            restored[user]['retweets_count']+= 1\n",
    "                    else:\n",
    "                        if suspended.get(user) is None:\n",
    "                            suspended[user]= {\n",
    "                                'hashtags': [j['text'] for j in i['entities']['hashtags']],\n",
    "                                'mentions': [j['id_str'] for j in i['entities']['user_mentions']],\n",
    "                                'tweets_count': 1,\n",
    "                                'retweets_count': 1\n",
    "                            }\n",
    "                        else:\n",
    "                            suspended[user]['tweets_count']+= 1\n",
    "                            suspended[user]['retweets_count']+= 1\n",
    "                elif i.get('full_text') or i.get('text'):\n",
    "                    if user in restoredUsersList:\n",
    "                        if restored.get(user) is None:\n",
    "                            restored[user]= {\n",
    "                                'hashtags': [j['text'] for j in i['entities']['hashtags']],\n",
    "                                'mentions': [j['id_str'] for j in i['entities']['user_mentions']],\n",
    "                                'tweets_count': 1,\n",
    "                                'retweets_count': 0\n",
    "                            }\n",
    "                        else:\n",
    "                            restored[user]['tweets_count']+= 1\n",
    "                            for j in i['entities']['hashtags']:\n",
    "                                restored[user]['hashtags'].append(j['text'])\n",
    "                            for j in i['entities']['user_mentions']:\n",
    "                                restored[user]['mentions'].append(j['id_str'])\n",
    "                    else:\n",
    "                        if suspended.get(user) is None:\n",
    "                            suspended[user]= {\n",
    "                                'hashtags': [j['text'] for j in i['entities']['hashtags']],\n",
    "                                'mentions': [j['id_str'] for j in i['entities']['user_mentions']],\n",
    "                                'tweets_count': 1,\n",
    "                                'retweets_count': 0\n",
    "                            }\n",
    "                        else:\n",
    "                            suspended[user]['tweets_count']+= 1\n",
    "                            for j in i['entities']['hashtags']:\n",
    "                                suspended[user]['hashtags'].append(j['text'])\n",
    "                            for j in i['entities']['user_mentions']:\n",
    "                                suspended[user]['mentions'].append(j['id_str'])\n",
    "                else:\n",
    "                    print('--'*20)\n",
    "                    pprint.pprint(i)\n",
    "                    break\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "someDump(normal, 'normal')\n",
    "someDump(suspended, 'suspended')\n",
    "someDump(restored, 'restored')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
