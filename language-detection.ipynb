{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, fasttext\n",
    "fmodel= fasttext.load_model('../data/lid.176.bin')\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm, re, pandas as pd, random, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(text):\n",
    "    temp= fmodel.predict([text])\n",
    "    temp_lang= temp[0][0][0]\n",
    "    temp_lang= temp_lang[temp_lang.index('__label__')+len('__label__'):]\n",
    "    return [temp_lang, temp[1][0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory():\n",
    "    status= open('/proc/self/status').read()\n",
    "    memuse= int(re.findall('VmRSS:\\s*(\\d+)\\skB', status)[0]) / 1024 ** 2\n",
    "    print('Resident memory: %.2f GB' % memuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPickle(name):\n",
    "    return pd.read_pickle(f'../data/{name}')\n",
    "def loadTxt(name):\n",
    "    return [i.strip() for i in open(f'../data/{name}', 'r').readlines()]\n",
    "def dumpPickle(df, name):\n",
    "    df.to_pickle(f'../data/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "restoredUsersList= set()\n",
    "for i in loadTxt('unsuspended_8_Oct.txt'):\n",
    "    restoredUsersList.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegB= loadPickle('Regular_Before_py37.pkl')\n",
    "RegA= loadPickle('Regular_After_py37.pkl')\n",
    "# Find the common users\n",
    "regularBefore= RegB[RegB['user.id_str'].isin(RegA['user.id_str'])].copy()\n",
    "regularAfter= RegA[RegA['user.id_str'].isin(RegB['user.id_str'])].copy()\n",
    "# Set the type of user\n",
    "regularBefore['typeOfUser']= 'regularBefore'\n",
    "regularAfter['typeOfUser']= 'regularAfter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResB= loadPickle('Restored_Before_py37.pkl')\n",
    "ResA= loadPickle('Restored_After_py37.pkl')\n",
    "# Find the common users\n",
    "restoredBefore= ResB[ResB['user.id_str'].isin(ResA['user.id_str'])==True].copy()\n",
    "restoredAfter= ResA[ResA['user.id_str'].isin(ResB['user.id_str'])==True].copy()\n",
    "# Set the type of user\n",
    "restoredBefore['typeOfUser']= 'restoredBefore'\n",
    "restoredAfter['typeOfUser']= 'restoredAfter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "pklDict= {\n",
    "    'restoredBefore': restoredBefore,\n",
    "    'restoredAfter': restoredAfter,\n",
    "    'regularBefore': regularBefore,\n",
    "    'regularAfter': regularAfter,\n",
    "}\n",
    "ResA= None\n",
    "ResB= None\n",
    "RegA= None\n",
    "RegB= None\n",
    "regularAfter= None\n",
    "restoredAfter= None\n",
    "regularBefore= None\n",
    "restoredBefore= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLanguageStats(dfName= None, df= None, name= ''):\n",
    "    temp= None\n",
    "    print('--'*20)\n",
    "    if dfName:\n",
    "        temp= pklDict[dfName][['lang', 'id_str']]\n",
    "        print(dfName)\n",
    "    else:\n",
    "        temp= df\n",
    "        if len(name)>0:\n",
    "            print(name)\n",
    "    print('Total Tweets:', len(temp.index))\n",
    "    print('No language detected tweets:', len(temp[temp['lang']=='und'].index))\n",
    "    print('Language detected tweets:', len(temp[temp['lang']!='und'].index))\n",
    "    print('Number of languages detected:', len(temp[temp['lang']!='und']['lang'].unique()))\n",
    "    temp_dict= dict(temp[temp['lang']!='und']['lang'].value_counts())\n",
    "    for i in temp_dict:\n",
    "        temp_dict[i]= (temp_dict[i]/len(temp[temp['lang']!='und'].index))*100\n",
    "    temp_dict= {k: v for k, v in sorted(temp_dict.items(), key=lambda item: item[1], reverse= True)}\n",
    "    print('*Top 5 languages*')\n",
    "    C= 0\n",
    "    for i in temp_dict:\n",
    "        print(i, f'{temp_dict[i]}%')\n",
    "        C+=1\n",
    "        if C==5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "printLanguageStats('restoredBefore')\n",
    "printLanguageStats('restoredAfter')\n",
    "printLanguageStats('regularBefore')\n",
    "printLanguageStats('regularAfter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_tweets= {'id_str': [], 'lang': [], 'accuracy_lang_detection': []}\n",
    "normal_dict= {}\n",
    "\n",
    "with open(f'../data/all_tweets_normal_jan3_2021.pickle', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            temp= pkl.load(f)\n",
    "            for i in tqdm.tqdm(temp):\n",
    "                # If it's a retweet\n",
    "                if i.get('retweeted_status'):\n",
    "                    # If it's an extended retweet\n",
    "                    if i['retweeted_status'].get('extended_tweet'):\n",
    "                        if i['retweeted_status']['extended_tweet'].get('full_text'):\n",
    "                            normal_tweets['id_str'].append(i['id_str'])\n",
    "                            try:\n",
    "                                tempDetect= detect(i['retweeted_status']['extended_tweet']['full_text'])\n",
    "                                normal_tweets['lang'].append(tempDetect[0])\n",
    "                                normal_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                            except:\n",
    "                                normal_tweets['lang'].append('und')\n",
    "                                normal_tweets['accuracy_lang_detection'].append(0)\n",
    "                        else:\n",
    "                            print('--Here--1--')\n",
    "                            pprint.pprint(i)\n",
    "                            break\n",
    "                    \n",
    "                    # If it's a retweet (non-extended)\n",
    "                    else:\n",
    "                        if i['retweeted_status'].get('full_text'):\n",
    "                            normal_tweets['id_str'].append(i['id_str'])\n",
    "                            try:\n",
    "                                tempDetect= detect(i['retweeted_status']['full_text'])\n",
    "                                normal_tweets['lang'].append(tempDetect[0])\n",
    "                                normal_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                            except:\n",
    "                                normal_tweets['lang'].append('und')\n",
    "                                normal_tweets['accuracy_lang_detection'].append(0)\n",
    "                                \n",
    "                        elif i['retweeted_status'].get('text'):\n",
    "                            normal_tweets['id_str'].append(i['id_str'])\n",
    "                            try:\n",
    "                                tempDetect= detect(i['retweeted_status']['text'])\n",
    "                                normal_tweets['lang'].append(tempDetect[0])\n",
    "                                normal_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                            except:\n",
    "                                normal_tweets['lang'].append('und')\n",
    "                                normal_tweets['accuracy_lang_detection'].append(0)\n",
    "                                \n",
    "                        else:\n",
    "                            print('--Here--2--')\n",
    "                            pprint.pprint(i)\n",
    "                            break\n",
    "                            \n",
    "                # If it's an original tweet (extended)\n",
    "                elif i.get('full_text'):\n",
    "                    normal_tweets['id_str'].append(i['id_str'])\n",
    "                    try:\n",
    "                        tempDetect= detect(i['full_text'])\n",
    "                        normal_tweets['lang'].append(tempDetect[0])\n",
    "                        normal_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                    except:\n",
    "                        normal_tweets['lang'].append('und')\n",
    "                        normal_tweets['accuracy_lang_detection'].append(0)\n",
    "                        \n",
    "                # If it's an original tweet (non-extended)\n",
    "                elif i.get('text'):\n",
    "                    normal_tweets['id_str'].append(i['id_str'])\n",
    "                    try:\n",
    "                        tempDetect= detect(i['text'])\n",
    "                        normal_tweets['lang'].append(tempDetect[0])\n",
    "                        normal_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                    except:\n",
    "                        normal_tweets['lang'].append('und')\n",
    "                        normal_tweets['accuracy_lang_detection'].append(0)\n",
    "                        \n",
    "                else:\n",
    "                    print('--Here--3--')\n",
    "                    pprint.pprint(i)\n",
    "                    break\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "suspended_tweets= {'id_str': [], 'lang': [], 'accuracy_lang_detection': []}\n",
    "suspended_dict= {}\n",
    "restored_tweets= {'id_str': [], 'lang': [], 'accuracy_lang_detection': []}\n",
    "restored_dict= {}\n",
    "\n",
    "with open(f'../data/all_tweets_suspended_jan3_2021.pickle', 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            temp= pkl.load(f)\n",
    "            for i in tqdm.tqdm(temp):\n",
    "                if i.get('retweeted_status'):\n",
    "                    if i['retweeted_status'].get('extended_tweet'):\n",
    "                        if i['retweeted_status']['extended_tweet'].get('full_text'):\n",
    "                            if i['user']['id_str'] in restoredUsersList:\n",
    "                                restored_tweets['id_str'].append(i['id_str'])\n",
    "                                try:\n",
    "                                    tempDetect= detect(i['retweeted_status']['extended_tweet']['full_text'])\n",
    "                                    restored_tweets['lang'].append(tempDetect[0])\n",
    "                                    restored_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                                except:\n",
    "                                    restored_tweets['lang'].append('und')\n",
    "                                    restored_tweets['accuracy_lang_detection'].append(0)\n",
    "                            else:\n",
    "                                suspended_tweets['id_str'].append(i['id_str'])\n",
    "                                try:\n",
    "                                    tempDetect= detect(i['retweeted_status']['extended_tweet']['full_text'])\n",
    "                                    suspended_tweets['lang'].append(tempDetect[0])\n",
    "                                    suspended_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                                except:\n",
    "                                    suspended_tweets['lang'].append('und')\n",
    "                                    suspended_tweets['accuracy_lang_detection'].append(0)\n",
    "                        else:\n",
    "                            print('--Here--1--')\n",
    "                            pprint.pprint(i)\n",
    "                            break\n",
    "                    else:\n",
    "                        if i['retweeted_status'].get('full_text'):\n",
    "                            if i['user']['id_str'] in restoredUsersList:\n",
    "                                restored_tweets['id_str'].append(i['id_str'])\n",
    "                                try:\n",
    "                                    tempDetect= detect(i['retweeted_status']['full_text'])\n",
    "                                    restored_tweets['lang'].append(tempDetect[0])\n",
    "                                    restored_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                                except:\n",
    "                                    restored_tweets['lang'].append('und')\n",
    "                                    restored_tweets['accuracy_lang_detection'].append(0)\n",
    "                            else:\n",
    "                                suspended_tweets['id_str'].append(i['id_str'])\n",
    "                                try:\n",
    "                                    tempDetect= detect(i['retweeted_status']['full_text'])\n",
    "                                    suspended_tweets['lang'].append(tempDetect[0])\n",
    "                                    suspended_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                                except:\n",
    "                                    suspended_tweets['lang'].append('und')\n",
    "                                    suspended_tweets['accuracy_lang_detection'].append(0)\n",
    "                        elif i['retweeted_status'].get('text'):\n",
    "                            if i['user']['id_str'] in restoredUsersList:\n",
    "                                restored_tweets['id_str'].append(i['id_str'])\n",
    "                                try:\n",
    "                                    tempDetect= detect(i['retweeted_status']['text'])\n",
    "                                    restored_tweets['lang'].append(tempDetect[0])\n",
    "                                    restored_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                                except:\n",
    "                                    restored_tweets['lang'].append('und')\n",
    "                                    restored_tweets['accuracy_lang_detection'].append(0)\n",
    "                            else:\n",
    "                                suspended_tweets['id_str'].append(i['id_str'])\n",
    "                                try:\n",
    "                                    tempDetect= detect(i['retweeted_status']['text'])\n",
    "                                    suspended_tweets['lang'].append(tempDetect[0])\n",
    "                                    suspended_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                                except:\n",
    "                                    suspended_tweets['lang'].append('und')\n",
    "                                    suspended_tweets['accuracy_lang_detection'].append(0)\n",
    "                        else:\n",
    "                            print('--Here--2--')\n",
    "                            pprint.pprint(i)\n",
    "                            break\n",
    "                elif i.get('full_text'):\n",
    "                    if i['user']['id_str'] in restoredUsersList:\n",
    "                        restored_tweets['id_str'].append(i['id_str'])\n",
    "                        try:\n",
    "                            tempDetect= detect(i['full_text'])\n",
    "                            restored_tweets['lang'].append(tempDetect[0])\n",
    "                            restored_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                        except:\n",
    "                            restored_tweets['lang'].append('und')\n",
    "                            restored_tweets['accuracy_lang_detection'].append(0)\n",
    "                    else:\n",
    "                        suspended_tweets['id_str'].append(i['id_str'])\n",
    "                        try:\n",
    "                            tempDetect= detect(i['full_text'])\n",
    "                            suspended_tweets['lang'].append(tempDetect[0])\n",
    "                            suspended_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                        except:\n",
    "                            suspended_tweets['lang'].append('und')\n",
    "                            suspended_tweets['accuracy_lang_detection'].append(0)\n",
    "                elif i.get('text'):\n",
    "                    if i['user']['id_str'] in restoredUsersList:\n",
    "                        restored_tweets['id_str'].append(i['id_str'])\n",
    "                        try:\n",
    "                            tempDetect= detect(i['text'])\n",
    "                            restored_tweets['lang'].append(tempDetect[0])\n",
    "                            restored_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                        except:\n",
    "                            restored_tweets['lang'].append('und')\n",
    "                            restored_tweets['accuracy_lang_detection'].append(0)\n",
    "                    else:\n",
    "                        suspended_tweets['id_str'].append(i['id_str'])\n",
    "                        try:\n",
    "                            tempDetect= detect(i['text'])\n",
    "                            suspended_tweets['lang'].append(tempDetect[0])\n",
    "                            suspended_tweets['accuracy_lang_detection'].append(tempDetect[1])\n",
    "                        except:\n",
    "                            suspended_tweets['lang'].append('und')\n",
    "                            suspended_tweets['accuracy_lang_detection'].append(0)\n",
    "                else:\n",
    "                    print('--Here--3--')\n",
    "                    pprint.pprint(i)\n",
    "                    break\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_tweets_df= pd.DataFrame.from_dict(normal_tweets).drop_duplicates('id_str')\n",
    "restored_tweets_df= pd.DataFrame.from_dict(restored_tweets).drop_duplicates('id_str')\n",
    "suspended_tweets_df= pd.DataFrame.from_dict(suspended_tweets).drop_duplicates('id_str')\n",
    "printLanguageStats(None, normal_tweets_df, 'Normal')\n",
    "printLanguageStats(None, restored_tweets_df, 'Restored')\n",
    "printLanguageStats(None, suspended_tweets_df, 'Suspended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "normal_dict, suspended_dict, restored_dict= {}, {}, {}\n",
    "for i, r in tqdm.tqdm(normal_tweets_df.iterrows()):\n",
    "    normal_dict[r['id_str']]= {\n",
    "        'lang': r['lang'],\n",
    "        'accuracy': r['accuracy_lang_detection']\n",
    "    }\n",
    "for i, r in tqdm.tqdm(suspended_tweets_df.iterrows()):\n",
    "    suspended_dict[r['id_str']]= {\n",
    "        'lang': r['lang'],\n",
    "        'accuracy': r['accuracy_lang_detection']\n",
    "    }\n",
    "for i, r in tqdm.tqdm(restored_tweets_df.iterrows()):\n",
    "    restored_dict[r['id_str']]= {\n",
    "        'lang': r['lang'],\n",
    "        'accuracy': r['accuracy_lang_detection']\n",
    "    }\n",
    "with open('./normal_tweets_lang_accuracy.json', 'w') as fp:\n",
    "    json.dump(normal_dict, fp, indent= 2)\n",
    "with open('./suspended_tweets_lang_accuracy.json', 'w') as fp:\n",
    "    json.dump(suspended_dict, fp, indent= 2)\n",
    "with open('./restored_tweets_lang_accuracy.json', 'w') as fp:\n",
    "    json.dump(restored_dict, fp, indent= 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
